{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importando las librerías requeridas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definiendo variables del entorno de trabajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = Path(\"/home/cmejia3\")\n",
    "datasetIn =basepath / \"datasets/papers-txt/\"\n",
    "datasetOut =basepath / \"datasets/salidas/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones para preprocesar los archivos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fileSize(fileIn):\n",
    "    size=os.stat(fileIn).st_size\n",
    "    return size\n",
    "\n",
    "def wordsCount(contenido):\n",
    "    totWwords=contenido.split()\n",
    "    return len(totWwords)\n",
    "\n",
    "def cleanWordCount(contenido,datasetOut):\n",
    "    contenido =re.sub('(f|ht)tp(s?)://(.*)[.][a-z]+',' ',contenido) # Eliminar las URL\n",
    "    #contenido =re.sub('REFERENCES (\\S|\\w)+',' ',contenido) # Eliminar la bibliografia\n",
    "    contenido =re.sub('[a-zA-Z0-9.?{}]+@\\w+\\.\\w+.\\w*',' ',contenido) # Eliminar los correos\n",
    "    contenido =re.sub('\\[[a-zA-Z0-9\\,\\. ]+\\]',' ',contenido) # Eliminar cualquier contenido entre corchetes\n",
    "    contenido =re.sub('\\([a-zA-Z0-9\\,\\.\\- ]+\\)',' ',contenido) # Eliminar cualquier contenido entre paréntesis\n",
    "    contenido =re.sub('((et al\\.)|(i\\.i\\.d\\.)|(i\\.e\\.)|\\-|\\'|\\’|\\`)',' ',contenido) # Eliminar abreviaciones, apostrofes y guion\n",
    "    #contenido =re.sub('(f|F)igure [0-9]+.[0-9]',' ',contenido) # Eliminar Figure\n",
    "    contenido =re.sub('[^a-zA-Z_á\\éíóúà\\èìòùäëïöü\\s]',' ',contenido) # Eliminar caracteres que no sean: letra, número o vocales acentuadas\n",
    "    contenido =re.sub(' +',' ',contenido) # Eliminar espacios en blanco\n",
    "    contenido =re.sub('(a-z|A-Z){1,1}',' ',contenido) # Eliminar palabras o números de un caracter de longitud   \n",
    "    #contenido =re.sub('[^A-Za-z0-9.,_%+-\\(\\)\\[\\]\\´\\'\\`]',' ',contenido)\n",
    "    #contenido =re.sub('\\[(0-9)+\\]',' ',contenido)    \n",
    "    #totWordDepurado = Counter(map(str, contenido.split()))\n",
    "    outputFile= open(datasetOut, 'w', encoding='UTF-8')\n",
    "    outputFile.write(contenido)\n",
    "    outputFile.close()\n",
    "    totWwords=contenido.split()\n",
    "    #print(\"Total de palabras {}\".format(len(totWwords)))\n",
    "    #print(\"Total de palabras después del pre-procesamiento: {}\".format(totWordDepurado))\n",
    "    return len(totWwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-procesamiento de archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileSummary = datasetOut / \"CleanSummary.csv\"\n",
    "\n",
    "contenido= \"Archivo\" + \";\" + \"Tamaño(K)\" + \";\" + \"Cant Palabras Inicial\" + \";\" + \"Cant Palabras depuradas\"+ \";\" +\"Porc Limpieza\"+ \"\\n\"\n",
    "resultado = pd.DataFrame()\n",
    "for f in datasetIn.glob('*.txt'):\n",
    "    tmpSize=round(fileSize(f)/1014)\n",
    "    input_file = open(f, \"r\", encoding = 'utf-8')\n",
    "    input_aux = input_file.read()\n",
    "    tmpWordsOri=wordsCount(input_aux)\n",
    "    out = datasetOut / str(f).split('/')[-1]\n",
    "    tmpWordsEnd=cleanWordCount(input_aux,out)\n",
    "    tmpPerClean=round((tmpWordsEnd/tmpWordsOri)*100)\n",
    "    aux= pd.DataFrame({'Archivo': str(f).split('/')[-1], 'Tamaño(K)': [tmpSize], 'Cant Palabras Inicial': [tmpWordsOri],'Cant Palabras depuradas': [tmpWordsEnd],\"Porc Limpieza\":[tmpPerClean]})\n",
    "    resultado = pd.concat([resultado, aux])\n",
    "\n",
    "resultado.to_csv(fileSummary, sep = ';', index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.6(conda)",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
