{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import udf, col, expr, when, concat, lit, isnan,struct\n",
    "import pyspark\n",
    "from pyspark.sql import SQLContext\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Al ejecutar esta celda se demora un poco, así que un poco de paciencia\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "sc = SparkContext('local', \"Articles_topic_model\") \n",
    "spark = SparkSession(sc)\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de Datos de Artículos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|          identifier|               title|         description|             subject|             creator|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|http://arxiv.org/...|Smooth R\\'enyi En...|  We prove that t...|Quantum Physics ;...|Schoenmakers, Ber...|\n",
      "|http://arxiv.org/...|Analyzing Design ...|  In the field of...|Computer Science ...|Brust, Matthias R...|\n",
      "|http://arxiv.org/...|Colour image segm...|  We propose a ne...|Computer Science ...|Kay, David A ; To...|\n",
      "|http://arxiv.org/...|Unequal Error Pro...|  An information ...|Computer Science ...|Borade, Shashi ; ...|\n",
      "|http://arxiv.org/...|On the hitting ti...|  In this paper w...|Quantum Physics ;...|Magniez, Frederic...|\n",
      "|http://arxiv.org/...|Coding Theory and...|  This chapter in...|Mathematics - Com...|   Huber, Michael ; |\n",
      "|http://arxiv.org/...|Generating Random...|  Random graph ge...|Computer Science ...|Bayati, Mohsen ; ...|\n",
      "|http://arxiv.org/...|Variations on a t...|  Schalkwijk and ...|Computer Science ...|Gallager, Robert ...|\n",
      "|http://arxiv.org/...|Rotation Distance...|  Rotation distan...|Computer Science ...|Cleary, Sean ; Jo...|\n",
      "|http://arxiv.org/...|A Linear-Time App...|  Rotation distan...|Computer Science ...|Cleary, Sean ; Jo...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfArticles=spark.read.csv(\"file:///home/ubuntu/3ra_entrega_PI/datasets/articles.csv\", inferSchema=True, header=True, encoding=\"UTF-8\")\n",
    "dfArticles.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conteo de las palabras iniciales que están en el título y en la descripcion de cada artículo\n",
    "\n",
    "def countWords(record):\n",
    "    textTitle  = record[1]\n",
    "    textDescription = record[2]\n",
    "    textCombined = textTitle + \" \" + textDescription\n",
    "    words = textCombined.split()\n",
    "    longitudTexto=len(words)\n",
    "    return longitudTexto\n",
    "\n",
    "udf_countWords = udf(countWords, IntegerType())\n",
    "dfcountWords = dfArticles.withColumn(\"countWords\", udf_countWords(struct([dfArticles[x] for x in dfArticles.columns])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(sum(countWords)=146184)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Total de palabras del título y de la descripción de los artículos\n",
    "totalWords = dfcountWords.agg(F.sum(\"countWords\")).collect()\n",
    "totalWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|          identifier|               title|         description|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|http://arxiv.org/...|Smooth R\\'enyi En...|  We prove that t...|\n",
      "|http://arxiv.org/...|Analyzing Design ...|  In the field of...|\n",
      "|http://arxiv.org/...|Colour image segm...|  We propose a ne...|\n",
      "|http://arxiv.org/...|Unequal Error Pro...|  An information ...|\n",
      "|http://arxiv.org/...|On the hitting ti...|  In this paper w...|\n",
      "|http://arxiv.org/...|Coding Theory and...|  This chapter in...|\n",
      "|http://arxiv.org/...|Generating Random...|  Random graph ge...|\n",
      "|http://arxiv.org/...|Variations on a t...|  Schalkwijk and ...|\n",
      "|http://arxiv.org/...|Rotation Distance...|  Rotation distan...|\n",
      "|http://arxiv.org/...|A Linear-Time App...|  Rotation distan...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Selección de las columnas relevantes\n",
    "\n",
    "dfMainCols= dfArticles.select('identifier','title','description')\n",
    "dfMainCols.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def cleanup_filename(record):\n",
    "#    textURL  = record[0]\n",
    "#    longURL =len(textURL)\n",
    "#    textFile =textURL[longURL-9:longURL]\n",
    "#    return textFile\n",
    "#udf_cleanfilename = udf(cleanup_filename, ArrayType(StringType()))\n",
    "#dfCleanFile = dfMainCols.withColumn(\"File\", udf_cleanfilename(struct([dfMainCols[x] for x in dfMainCols.columns])))\n",
    "#dfCleanFile.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#textfile=\"http://arxiv.org/abs/0704.3504\"\n",
    "#longURL=len(textfile)\n",
    "#tfile=textfile[longURL-9:longURL]\n",
    "#print(tfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import IDF, Tokenizer, CountVectorizer\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.linalg import Vectors, SparseVector\n",
    "from pyspark.ml.clustering import LDA, BisectingKMeans\n",
    "#from pyspark.sql.functions import monotonically_increasing_id\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import codecs\n",
    "#import matplotlib.pyplot as plt\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "nltk.download(['stopwords'])\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up list of Stopwords\n",
    "stopWords1 = stopwords.words('english')\n",
    "\n",
    "stopwords2 = [word.lower() for word in stopWords1] \n",
    "\n",
    "#Stemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def cleanup_text(record):\n",
    "    textTitle  = record[1]\n",
    "    textDescription = record[2]\n",
    "    # Remove special characters\n",
    "    textCombined = textTitle + \" \" + textDescription\n",
    "    textCombined = re.sub('(-|-|\\u2212|\\u2012|\\u2013|\\u2014|\\u2015)\\n','',textCombined)\n",
    "    textCombined = re.sub('(-|-|\\u2212|\\u2012|\\u2013|\\u2014|\\u2015)',' ',textCombined)\n",
    "    textCombined = re.sub('[^a-zA-Z]',' ',textCombined) \n",
    "    words = textCombined.split()\n",
    "    # Remove stopwords and words under 3 length\n",
    "    tokens3 = [word.lower() for word in words if len(word)>3 and word.lower() not in stopwords2] \n",
    "    text_out = [ps.stem(w) for w in tokens3]\n",
    "    return text_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "udf_tokensCombined = udf(cleanup_text, ArrayType(StringType()))\n",
    "dfCombined = dfMainCols.withColumn(\"tokensCombined\", udf_tokensCombined(struct([dfMainCols[x] for x in dfMainCols.columns])))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|          identifier|               title|         description|      tokensCombined|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|http://arxiv.org/...|Smooth R\\'enyi En...|  We prove that t...|[smooth, enyi, en...|\n",
      "|http://arxiv.org/...|Analyzing Design ...|  In the field of...|[analyz, design, ...|\n",
      "|http://arxiv.org/...|Colour image segm...|  We propose a ne...|[colour, imag, se...|\n",
      "|http://arxiv.org/...|Unequal Error Pro...|  An information ...|[unequ, error, pr...|\n",
      "|http://arxiv.org/...|On the hitting ti...|  In this paper w...|[hit, time, quant...|\n",
      "|http://arxiv.org/...|Coding Theory and...|  This chapter in...|[code, theori, al...|\n",
      "|http://arxiv.org/...|Generating Random...|  Random graph ge...|[gener, random, n...|\n",
      "|http://arxiv.org/...|Variations on a t...|  Schalkwijk and ...|[variat, theme, s...|\n",
      "|http://arxiv.org/...|Rotation Distance...|  Rotation distan...|[rotat, distanc, ...|\n",
      "|http://arxiv.org/...|A Linear-Time App...|  Rotation distan...|[linear, time, ap...|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfCombined.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countTokens(record):\n",
    "    listTokens = record[3]\n",
    "    #words = textTitle.split(\",\")\n",
    "    numTokens=len(listTokens)\n",
    "    return numTokens\n",
    "\n",
    "udf_countTokens = udf(countTokens, IntegerType())\n",
    "dfcountTokens = dfCombined.withColumn(\"countTokens\", udf_countTokens(struct([dfCombined[x] for x in dfCombined.columns])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+-----------+\n",
      "|          identifier|               title|         description|      tokensCombined|countTokens|\n",
      "+--------------------+--------------------+--------------------+--------------------+-----------+\n",
      "|http://arxiv.org/...|Smooth R\\'enyi En...|  We prove that t...|[smooth, enyi, en...|         33|\n",
      "|http://arxiv.org/...|Analyzing Design ...|  In the field of...|[analyz, design, ...|         95|\n",
      "|http://arxiv.org/...|Colour image segm...|  We propose a ne...|[colour, imag, se...|         66|\n",
      "|http://arxiv.org/...|Unequal Error Pro...|  An information ...|[unequ, error, pr...|         69|\n",
      "|http://arxiv.org/...|On the hitting ti...|  In this paper w...|[hit, time, quant...|        113|\n",
      "|http://arxiv.org/...|Coding Theory and...|  This chapter in...|[code, theori, al...|         61|\n",
      "|http://arxiv.org/...|Generating Random...|  Random graph ge...|[gener, random, n...|        104|\n",
      "|http://arxiv.org/...|Variations on a t...|  Schalkwijk and ...|[variat, theme, s...|         99|\n",
      "|http://arxiv.org/...|Rotation Distance...|  Rotation distan...|[rotat, distanc, ...|         46|\n",
      "|http://arxiv.org/...|A Linear-Time App...|  Rotation distan...|[linear, time, ap...|         42|\n",
      "|http://arxiv.org/...|The quantum query...|  We study the qu...|[quantum, queri, ...|         46|\n",
      "|http://arxiv.org/...|On uncertainty pr...|  The aim of this...|[uncertainti, pri...|         35|\n",
      "|http://arxiv.org/...|Error-and-Erasure...|  Inner and outer...|[error, erasur, d...|         94|\n",
      "|http://arxiv.org/...|Joint-sparse reco...|  The joint-spars...|[joint, spars, re...|         82|\n",
      "|http://arxiv.org/...|Inter Genre Simil...|  Music genre cla...|[inter, genr, sim...|         86|\n",
      "|http://arxiv.org/...|       P != NP Proof|  This paper demo...|[proof, paper, de...|         66|\n",
      "|http://arxiv.org/...|Universally Compo...|  The Universal C...|[univers, compos,...|         58|\n",
      "|http://arxiv.org/...|On the stability ...|  We consider fiv...|[stabil, chunk, f...|         61|\n",
      "|http://arxiv.org/...|MAC Layer Hurdles...|  The last few de...|[layer, hurdl, bs...|         95|\n",
      "|http://arxiv.org/...|On the Developmen...|  Current advance...|[develop, power, ...|         73|\n",
      "+--------------------+--------------------+--------------------+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfcountTokens.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(sum(countTokens)=84576)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalTokens = dfcountTokens.agg(F.sum(\"countTokens\")).collect()\n",
    "totalTokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfvocab=dfcountTokens.select(\"tokensCombined\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5483"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabArticles = set()\n",
    "fil,col=dfvocab.shape\n",
    "#print(\"Dimensiones de filas {} y de columnas {} de dataframe\".format(fil,col))\n",
    "#in workVoc.iloc[:,0]:\n",
    "for i in range(fil): \n",
    "    vocabArticles = vocabArticles.union(set(dfvocab.iloc[i,0]))\n",
    "len(vocabArticles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pendiente Hacer el conteo de palabras que quedaron.\n",
    "# Implementar SVD para reducción de la dimensionalidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def setVocab (record):\n",
    "#    listTokens = record[3]\n",
    "#    #words = textTitle.split(\",\")\n",
    "#    numTokens=len(listTokens)\n",
    "#    return numTokens\n",
    "\n",
    "#udf_setVocab = udf(setVocab, IntegerType())\n",
    "#dfsetVocab = dfcountTokens.withColumn(\"setVocab\", udf_setVocab(struct([dfcountTokens[x] for x in dfcountTokens.columns])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2252"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Term Frequency Vectorization: \n",
    "cvTokensCombined = CountVectorizer(inputCol=\"tokensCombined\", outputCol=\"rawFeatures\", minDF = 3, vocabSize = 4000)\n",
    "cvmodel = cvTokensCombined.fit(dfCombined)\n",
    "featurizedData = cvmodel.transform(dfCombined)\n",
    "\n",
    "vocab = cvmodel.vocabulary\n",
    "vocab_broadcast = sc.broadcast(vocab)\n",
    "\n",
    "#Longitud del Vocabulario del BoW\n",
    "len(cvmodel.vocabulary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#featurizedData.select(\"rawFeatures\").toPandas().to_csv(\"featurizedData.csv\", header=True)\n",
    "dfFeatures=featurizedData.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(2252, {23: 4.0, 27: 1.0, 48: 1.0, 88: 4.0, 114: 2.0, 143: 1.0, 199: 1.0, 268: 4.0, 373: 5.0, 429: 1.0, 644: 2.0, 1046: 2.0, 1128: 1.0, 1279: 1.0, 1602: 1.0, 1693: 1.0})"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfFeatures.iloc[0,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating IDF\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "rescaledData = idfModel.transform(featurizedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|          identifier|               title|         description|            features|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|http://arxiv.org/...|Smooth R\\'enyi En...|  We prove that t...|(2252,[23,27,48,8...|\n",
      "|http://arxiv.org/...|Analyzing Design ...|  In the field of...|(2252,[1,9,11,12,...|\n",
      "|http://arxiv.org/...|Colour image segm...|  We propose a ne...|(2252,[1,2,3,9,12...|\n",
      "|http://arxiv.org/...|Unequal Error Pro...|  An information ...|(2252,[9,19,20,21...|\n",
      "|http://arxiv.org/...|On the hitting ti...|  In this paper w...|(2252,[0,1,3,4,8,...|\n",
      "|http://arxiv.org/...|Coding Theory and...|  This chapter in...|(2252,[1,9,16,29,...|\n",
      "|http://arxiv.org/...|Generating Random...|  Random graph ge...|(2252,[0,1,2,3,4,...|\n",
      "|http://arxiv.org/...|Variations on a t...|  Schalkwijk and ...|(2252,[3,9,20,28,...|\n",
      "|http://arxiv.org/...|Rotation Distance...|  Rotation distan...|(2252,[0,4,7,10,1...|\n",
      "|http://arxiv.org/...|A Linear-Time App...|  Rotation distan...|(2252,[0,4,7,16,2...|\n",
      "|http://arxiv.org/...|The quantum query...|  We study the qu...|(2252,[10,12,20,2...|\n",
      "|http://arxiv.org/...|On uncertainty pr...|  The aim of this...|(2252,[4,8,9,10,1...|\n",
      "|http://arxiv.org/...|Error-and-Erasure...|  Inner and outer...|(2252,[3,14,18,20...|\n",
      "|http://arxiv.org/...|Joint-sparse reco...|  The joint-spars...|(2252,[0,1,3,10,1...|\n",
      "|http://arxiv.org/...|Inter Genre Simil...|  Music genre cla...|(2252,[1,2,9,11,1...|\n",
      "|http://arxiv.org/...|       P != NP Proof|  This paper demo...|(2252,[1,7,11,14,...|\n",
      "|http://arxiv.org/...|Universally Compo...|  The Universal C...|(2252,[2,7,10,14,...|\n",
      "|http://arxiv.org/...|On the stability ...|  We consider fiv...|(2252,[0,9,10,17,...|\n",
      "|http://arxiv.org/...|MAC Layer Hurdles...|  The last few de...|(2252,[6,8,11,15,...|\n",
      "|http://arxiv.org/...|On the Developmen...|  Current advance...|(2252,[6,8,11,15,...|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rescaledData.select('identifier','title','description','features').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 20 Data-Driven Topics:\n",
    "lda = LDA(k=20, seed=123, optimizer=\"em\", featuresCol=\"features\")\n",
    "\n",
    "ldamodel = lda.fit(rescaledData)\n",
    "\n",
    "#model.isDistributed()\n",
    "#model.vocabSize()\n",
    "\n",
    "ldatopics = ldamodel.describeTopics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|          identifier|               title|      tokensCombined|            features|   topicDistribution|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|http://arxiv.org/...|Smooth R\\'enyi En...|[smooth, enyi, en...|(2252,[23,27,48,8...|[0.02562707864610...|\n",
      "|http://arxiv.org/...|Analyzing Design ...|[analyz, design, ...|(2252,[1,9,11,12,...|[0.01993572074744...|\n",
      "|http://arxiv.org/...|Colour image segm...|[colour, imag, se...|(2252,[1,2,3,9,12...|[0.03759360230722...|\n",
      "|http://arxiv.org/...|Unequal Error Pro...|[unequ, error, pr...|(2252,[9,19,20,21...|[0.04054565049418...|\n",
      "|http://arxiv.org/...|On the hitting ti...|[hit, time, quant...|(2252,[0,1,3,4,8,...|[0.01990665797540...|\n",
      "|http://arxiv.org/...|Coding Theory and...|[code, theori, al...|(2252,[1,9,16,29,...|[0.02439916890143...|\n",
      "|http://arxiv.org/...|Generating Random...|[gener, random, n...|(2252,[0,1,2,3,4,...|[0.07654444660137...|\n",
      "|http://arxiv.org/...|Variations on a t...|[variat, theme, s...|(2252,[3,9,20,28,...|[0.05218247613870...|\n",
      "|http://arxiv.org/...|Rotation Distance...|[rotat, distanc, ...|(2252,[0,4,7,10,1...|[0.04012868172328...|\n",
      "|http://arxiv.org/...|A Linear-Time App...|[linear, time, ap...|(2252,[0,4,7,16,2...|[0.02946657334018...|\n",
      "|http://arxiv.org/...|The quantum query...|[quantum, queri, ...|(2252,[10,12,20,2...|[0.02446449506127...|\n",
      "|http://arxiv.org/...|On uncertainty pr...|[uncertainti, pri...|(2252,[4,8,9,10,1...|[0.11020079858139...|\n",
      "|http://arxiv.org/...|Error-and-Erasure...|[error, erasur, d...|(2252,[3,14,18,20...|[0.02902178608091...|\n",
      "|http://arxiv.org/...|Joint-sparse reco...|[joint, spars, re...|(2252,[0,1,3,10,1...|[0.03074605162966...|\n",
      "|http://arxiv.org/...|Inter Genre Simil...|[inter, genr, sim...|(2252,[1,2,9,11,1...|[0.01344714052305...|\n",
      "|http://arxiv.org/...|       P != NP Proof|[proof, paper, de...|(2252,[1,7,11,14,...|[0.07669510392098...|\n",
      "|http://arxiv.org/...|Universally Compo...|[univers, compos,...|(2252,[2,7,10,14,...|[0.04151356255037...|\n",
      "|http://arxiv.org/...|On the stability ...|[stabil, chunk, f...|(2252,[0,9,10,17,...|[0.02459350540607...|\n",
      "|http://arxiv.org/...|MAC Layer Hurdles...|[layer, hurdl, bs...|(2252,[6,8,11,15,...|[0.02500836841471...|\n",
      "|http://arxiv.org/...|On the Developmen...|[develop, power, ...|(2252,[6,8,11,15,...|[0.02382750796754...|\n",
      "|http://arxiv.org/...|Towards Power Eff...|[toward, power, e...|(2252,[6,8,11,12,...|[0.02905044266898...|\n",
      "|http://arxiv.org/...|A Study of Implan...|[studi, implant, ...|(2252,[4,6,11,17,...|[0.01466794400985...|\n",
      "|http://arxiv.org/...|Euclidean versus ...|[euclidean, versu...|(2252,[2,6,8,11,1...|[0.01319206407711...|\n",
      "|http://arxiv.org/...|Model Selection: ...|[model, select, f...|(2252,[0,1,2,11,1...|[0.01451507148347...|\n",
      "|http://arxiv.org/...|Self-Reference Ul...|[self, refer, ult...|(2252,[3,9,10,13,...|[0.01805406117207...|\n",
      "|http://arxiv.org/...|JBotSim, a Tool f...|[jbotsim, tool, f...|(2252,[0,3,6,11,1...|[0.03859449835746...|\n",
      "|http://arxiv.org/...|Combinatorial Bou...|[combinatori, bou...|(2252,[8,9,14,16,...|[0.04275699714458...|\n",
      "|http://arxiv.org/...|Efficient Bayesia...|[effici, bayesian...|(2252,[3,4,5,6,7,...|[0.01297102397864...|\n",
      "|http://arxiv.org/...|Having Fun with L...|[lambert, functio...|(2252,[21,22,33,3...|[0.04394028154981...|\n",
      "|http://arxiv.org/...|Delay-rate tradeo...|[delay, rate, tra...|(2252,[4,6,10,11,...|[0.02915956619548...|\n",
      "|http://arxiv.org/...|FauxCrypt - A Met...|[fauxcrypt, metho...|(2252,[0,7,12,14,...|[0.02493320032557...|\n",
      "|http://arxiv.org/...|Optimal Gradient ...|[optim, gradient,...|(2252,[0,1,4,5,6,...|[0.01361984362084...|\n",
      "|http://arxiv.org/...|A Proof for P =? ...|[proof, problem, ...|(2252,[1,7,11,15,...|[0.09755939615757...|\n",
      "|http://arxiv.org/...|Why Gabor Frames?...|[gabor, frame, fu...|(2252,[0,2,3,8,9,...|[0.00987980843670...|\n",
      "|http://arxiv.org/...|Chi-square-based ...|[squar, base, sco...|(2252,[0,3,8,9,12...|[0.01736285805309...|\n",
      "|http://arxiv.org/...|Rasch-based high-...|[rasch, base, hig...|(2252,[1,2,3,8,9,...|[0.01155012624048...|\n",
      "|http://arxiv.org/...|Computational com...|[comput, complex,...|(2252,[0,1,4,5,7,...|[0.03409531840488...|\n",
      "|http://arxiv.org/...|The Coarsest Prec...|[coarsest, precon...|(2252,[11,17,54,7...|[0.04225293131145...|\n",
      "|http://arxiv.org/...|Identification of...|[identif, paramet...|(2252,[0,1,3,4,8,...|[0.01549926098874...|\n",
      "|http://arxiv.org/...|Some Theorems on ...|[theorem, algorit...|(2252,[0,4,9,16,2...|[0.04853180392062...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 40 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ldaResults = ldamodel.transform(rescaledData)\n",
    "\n",
    "ldaResults.select('identifier','title','tokensCombined','features','topicDistribution').show(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#featurizedData.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------------------------------------------------------------------------+\n",
      "|topic|topic_desc                                                                            |\n",
      "+-----+--------------------------------------------------------------------------------------+\n",
      "|0    |[mathbb, finit, size, induc, length, subgraph, sequenc, theorem, width, fix]          |\n",
      "|1    |[learn, task, classif, train, method, statist, fit, data, decis, model]               |\n",
      "|2    |[network, node, measur, small, world, navig, encod, estim, transform, grid]           |\n",
      "|3    |[game, strategi, player, action, equilibrium, seed, stabil, resourc, period, nash]    |\n",
      "|4    |[nois, align, imag, track, filter, particl, risk, block, admm, counter]               |\n",
      "|5    |[pattern, model, social, infer, rank, spread, predict, chang, influenc, network]      |\n",
      "|6    |[graph, tree, edg, planar, spectral, vertic, match, bound, problem, cluster]          |\n",
      "|7    |[color, delta, graph, frac, point, equat, beta, node, cubic, fault]                   |\n",
      "|8    |[model, design, program, iter, emph, tempor, convex, minim, solut, comput]            |\n",
      "|9    |[control, spars, cell, abstract, sens, local, sensor, compress, recoveri, system]     |\n",
      "|10   |[error, attack, detect, polar, cloud, full, patch, nearest, learn, decod]             |\n",
      "|11   |[commun, curv, modular, qualiti, self, observ, metric, coeffici, inform, face]        |\n",
      "|12   |[quantum, mechan, proof, differenti, good, classic, agent, probabilist, item, privaci]|\n",
      "|13   |[protocol, logic, queri, epsilon, time, algorithm, stabl, belief, group, approxim]    |\n",
      "|14   |[code, dimens, data, softwar, dictionari, structur, activ, dual, content, human]      |\n",
      "|15   |[mathcal, alpha, lambda, packet, biolog, channel, capac, type, column, equit]         |\n",
      "|16   |[sampl, matrix, video, privaci, select, kernel, averag, target, user, data]           |\n",
      "|17   |[channel, signal, user, relay, estim, mimo, rate, receiv, transmiss, inform]          |\n",
      "|18   |[matric, load, circuit, famili, traffic, system, input, notion, random, complex]      |\n",
      "|19   |[languag, energi, word, loss, aggreg, order, signatur, agent, secur, group]           |\n",
      "+-----+--------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def map_termID_to_Word(termIndices):\n",
    "    words = []\n",
    "    for termID in termIndices:\n",
    "        words.append(vocab_broadcast.value[termID])\n",
    "    \n",
    "    return words\n",
    "\n",
    "udf_map_termID_to_Word = udf(map_termID_to_Word , ArrayType(StringType()))\n",
    "ldatopics_mapped = ldatopics.withColumn(\"topic_desc\", udf_map_termID_to_Word(ldatopics.termIndices))\n",
    "ldatopics_mapped.select(ldatopics_mapped.topic, ldatopics_mapped.topic_desc).show(20,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldatopics_mapped.select('topic','topic_desc').toPandas().to_csv(\"lda_topics_articles.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "def asignTopic(topicDistribution):\n",
    "    topic = topicDistribution[0]\n",
    "    index_topic = 0\n",
    "    for index in range(len(topicDistribution)):\n",
    "        if (topicDistribution[index]>topic):\n",
    "            topic=topicDistribution[index]\n",
    "            index_topic=index\n",
    "    return index_topic\n",
    "\n",
    "udf_asignTopic = udf(asignTopic, IntegerType())\n",
    "dfMainTopic = ldaResults.withColumn(\"mainTopic\", udf_asignTopic(ldaResults.topicDistribution))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['identifier',\n",
       " 'title',\n",
       " 'description',\n",
       " 'tokensCombined',\n",
       " 'rawFeatures',\n",
       " 'features',\n",
       " 'topicDistribution',\n",
       " 'mainTopic']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfMainTopic.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMainTopic.select('identifier','title','tokensCombined','mainTopic').toPandas().to_csv(\"ldaresults_articles.csv\", header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agrupamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from math import sqrt\n",
    "from pyspark.ml.feature import Normalizer\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.clustering import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescaledData.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizando los datos calculando el TF-IDF, penalizando\n",
    "normalizer = Normalizer(inputCol=\"features\", outputCol=\"normFeatures\")\n",
    "l2NormData = normalizer.transform(rescaledData)\n",
    "\n",
    "#Entrenando el modelo de K-means\n",
    "kClusters=20\n",
    "kmparmeter = KMeans().setK(kClusters).setMaxIter(20)\n",
    "km_model = kmparmeter.fit(l2NormData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.linalg.distributed import RowMatrix\n",
    "\n",
    "mat = RowMatrix(rescaledData.select(\"features\"))\n",
    "# Compute the top 5 singular values and corresponding singular vectors.\n",
    "\n",
    "svd = mat.computeSVD(5, computeU=True)\n",
    "U = svd.U # The U factor is a RowMatrix.\n",
    "s = svd.s # The singular values are stored in a local dense vector.\n",
    "V = svd.V # The V factor is a local dense matrix.\n",
    "## $example off$\n",
    "collected = U.rows.collect()\n",
    "print(\"U factor is:\")\n",
    "for vector in collected:\n",
    "    print(vector)\n",
    "    print(\"Singular values are: %s\" % s)\n",
    "    print(\"V factor is:\\n%s\" % V)\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustersTable = km_model.transform(l2NormData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustersTable.toPandas().to_csv(\"clustertable_articles.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustersTable.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustersTable.select('identifier','title','tokensCombined','normFeatures','prediction').show(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustersTable.registerTempTable(\"Clusters\")\n",
    "df2 = sqlContext.sql(\"select prediction from Clusters group by prediction\")\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
