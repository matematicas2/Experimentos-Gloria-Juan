{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpieza de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/cmejia3/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/cmejia3/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/cmejia3/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package words to /home/cmejia3/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import re\n",
    "import nltk\n",
    "nltk.download(['punkt','stopwords','wordnet','words'])\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import *\n",
    "from nltk.corpus import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path =  Path(\"~\").expanduser().resolve()\n",
    "#base_path = Path.cwd().expanduser().resolve()\n",
    "input_file_path  = base_path / 'datasets/papers-txt/'\n",
    "#datasetOut =base_path / \"datasets/salidas_procesamiento/\"\n",
    "#datasetOut_freq = base_path / \"datasets/salidas_freq/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/cmejia3/datasets/papers-txt')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher= re.compile(r'(.)\\1*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher= re.compile(r'(.)\\1*')\n",
    "tot = [len(match.group()) for match in matcher.finditer('aaaadaaacbbabqq')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fileSize(fileIn):\n",
    "    size=os.stat(fileIn).st_size\n",
    "    return size\n",
    "\n",
    "def wordsCount(contenido):\n",
    "    totWwords=contenido.split()\n",
    "    return len(totWwords)\n",
    "\n",
    "def cleanWordCount(contenido):\n",
    "    contenido =re.sub('(f|ht)tp(s?)://(.*)[.][a-z]+',' ',contenido) # Eliminar las URL\n",
    "    #contenido =re.sub('REFERENCES (\\S|\\w)+',' ',contenido) # Eliminar la bibliografia\n",
    "    contenido =re.sub('[a-zA-Z0-9.?{}]+@\\w+\\.\\w+.\\w*','',contenido) # Eliminar los correos\n",
    "    contenido =re.sub('\\[[a-zA-Z0-9\\,\\. ]+\\]','',contenido) # Eliminar cualquier contenido entre corchetes\n",
    "    contenido =re.sub('\\([a-zA-Z0-9\\,\\.\\- ]+\\)',' ',contenido) # Eliminar cualquier contenido entre paréntesis\n",
    "    contenido =re.sub('((et al\\.)|(i\\.i\\.d\\.)|(i\\.e\\.)|\\-|\\'|\\’|\\`)','',contenido) # Eliminar abreviaciones, apostrofes y guion\n",
    "    #contenido =re.sub('(f|F)igure [0-9]+.[0-9]',' ',contenido) # Eliminar Figure\n",
    "    contenido =re.sub('[^a-zA-Z_á\\éíóúà\\èìòùäëïöü\\s]','',contenido) # Eliminar caracteres que no sean: letra, número o vocales acentuadas\n",
    "    contenido =re.sub(' +',' ',contenido) # Eliminar espacios en blanco\n",
    "    contenido =re.sub('(a-z|A-Z){1,1}','',contenido) # Eliminar palabras o números de un caracter de longitud   \n",
    "    #contenido =re.sub('[^A-Za-z0-9.,_%+-\\(\\)\\[\\]\\´\\'\\`]',' ',contenido)\n",
    "    #contenido =re.sub('\\[(0-9)+\\]',' ',contenido)    \n",
    "    #totWordDepurado = Counter(map(str, contenido.split()))\n",
    "    #outputFile= open(datasetOut, 'w', encoding='UTF-8')\n",
    "    #outputFile.write(contenido)\n",
    "    #outputFile.close()\n",
    "    totWwords=contenido.split()\n",
    "    setWords = set(totWwords)\n",
    "    #print(\"Total de palabras {}\".format(len(totWwords)))\n",
    "    #print(\"Total de palabras después del pre-procesamiento: {}\".format(totWordDepurado))\n",
    "    return len(totWwords),contenido,setWords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lang_ratio(input):\n",
    "    lang_ratio = {}\n",
    "    tokens = wordpunct_tokenize(input)\n",
    "    words = [word.lower() for word in tokens]\n",
    "    for language in stopwords.fileids():\n",
    "        stopwords_set = set(stopwords.words(language))\n",
    "        word_set = set(words)\n",
    "        common_elements = word_set.intersection(stopwords_set)\n",
    "        lang_ratio[language] = len(common_elements)\n",
    "    return lang_ratio\n",
    "\n",
    "def detect_language(input):\n",
    "    ratios = lang_ratio(input)\n",
    "    language = max(ratios, key = ratios.get)\n",
    "    return language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conjunto de las stop words que serán eliminadas ya que no aportan valor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Palabras que considermos StopWords que no estan incluidas en el conjunto descargado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "listoStopWords = ['www','https','html','figure', 'chapter','abbcbccabcabcabcabcbcbabacba']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se añaden las palabras que consideramos al conjunto principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWords.extend(listoStopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictonary = nltk.corpus.words.words()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función principal procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_files(texto,stopWords):\n",
    "    \n",
    "    #Quitar todos los acentos\n",
    "    #texto = unidecode.unidecode(texto)\n",
    "    \n",
    "    #Quitar todos los caracteres especiales\n",
    "    texto = re.sub('[^A-Za-z0-9]+',' ',texto)\n",
    "    \n",
    "    #Pasar todo a minisculas\n",
    "    texto = texto.lower()\n",
    "    \n",
    "    #Tokenizar\n",
    "    tokens = texto.split()\n",
    "    \n",
    "    #Variable que guarda el año en el que estamos que es el limite superior de los números que no se van a eliminar\n",
    "    currentYear = int(dt.datetime.now().year)\n",
    "    \n",
    "    #Verificar que las palabras tengan más de un caracter, que además sean solo sean letras\n",
    "    # o si son números que esten entre un rango que sea admisible para no eliminar información de año que se mencione en los artículos\n",
    "    # y finalmente que no sean palabras que estan en el dicccionario de stopwords.\n",
    "    \n",
    "    #tokens = [w for w in tokens if (len(w)>1)&(w.isalpha() or (w.isnumeric() and int(w)>=1800 and int(w)<=currentYear))&(w not in stopWords)]\n",
    "    tokens = [w for w in tokens if (len(w)>1)&(w.isalpha())&(w not in stopWords)]\n",
    "    \n",
    "    matcher= re.compile(r'(.)\\1*')\n",
    "    tokens1 = []\n",
    "    for word in tokens:\n",
    "        aux = [len(match.group()) for match in matcher.finditer(word)]\n",
    "        if max(aux)<=3:\n",
    "            tokens1.append(word)\n",
    "        else:\n",
    "            print(word)\n",
    "    \n",
    "    \n",
    "    tokens1 = [w for w in tokens1 if (Counter(w).most_common(1)[0][1]<5)]\n",
    "    eliminadas = [w for w in tokens1 if (Counter(w).most_common(1)[0][1]>=5)]\n",
    "    #Stemmer\n",
    "    ps = PorterStemmer() \n",
    "    tokens1 = [ps.stem(w) for w in tokens1]\n",
    "    \n",
    "    #Lematización\n",
    "    word_net_lemmatizar = WordNetLemmatizer()\n",
    "\n",
    "    tokens1 = [word_net_lemmatizar.lemmatize(w, pos = \"v\") for w in tokens1]\n",
    "    \n",
    "    #Se retorna el texto nuevamente en un solo string luego de ser procesado\n",
    "    to_return = ' '.join(tokens1)\n",
    "    \n",
    "    #Se retorna el vocabulario de cada documento\n",
    "    set_words = set(tokens1)\n",
    "    \n",
    "    #Y la frecuencia de las palabras\n",
    "    freq = nltk.FreqDist(tokens1)\n",
    "    return to_return,set_words,freq,eliminadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialización de los conjuntos:\n",
    "\n",
    "    - Vocabulary: el conjunto de todas las palabras que contienen los documentos\n",
    "    - results_text: la lista con los documentos ya organizados para construir el bag of words\n",
    "    - results_frecuency: información de cada documento de las palabras que contiene cuántas veces las contiene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = set()\n",
    "results_text = []\n",
    "results_frecuency = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fileSummary = \"CleanSummary_copy.csv\"\n",
    "\n",
    "contenido= \"Archivo\" + \";\" + \"Tamaño(K)\" + \";\" + \"Cant Palabras Inicial\" + \";\" + \"Cant Palabras depuradas\"+ \";\" +\"Porc Limpieza\"+ \"\\n\"\n",
    "resultado = pd.DataFrame()\n",
    "indexFiles = []\n",
    "documents = []\n",
    "i = 0\n",
    "for f in input_file_path.glob('*.txt'):\n",
    "    #Peso del archivo\n",
    "    tmpSize=round(fileSize(f)/1014)\n",
    "    \n",
    "    #Lectura del archivo\n",
    "    input_file = open(f, \"r\", encoding = 'utf-8')\n",
    "    input_aux = input_file.read()\n",
    "    \n",
    "    #Cuenta de palabras iniciales\n",
    "    tmpWordsOri=wordsCount(input_aux)\n",
    "    #out = datasetOut / str(f).split('/')[-1]\n",
    "    \n",
    "    #Cuenta de palabras despues de la limpieza\n",
    "    tmpWordsEnd,text,setWord=cleanWordCount(input_aux)\n",
    "    #tmpPerClean=round((tmpWordsEnd/tmpWordsOri)*100)\n",
    "    \n",
    "    \n",
    "    #Detectando el idioma\n",
    "    aux = detect_language(text)\n",
    "    \n",
    "    if(aux == 'english'):\n",
    "        i = i+1\n",
    "        text_cleanned,set_words,freq,eliminadas = clean_files(text,stopWords)\n",
    "        if len(eliminadas)> 0:\n",
    "            print(eliminadas)\n",
    "        #out2 = datasetOut / str(f).split('/')[-1]\n",
    "        documents.append(text_cleanned)\n",
    "        vocabulary = vocabulary.union(set_words)\n",
    "        results_text.append(text_cleanned)\n",
    "        indexFiles.append(str(f).split('/')[-1])\n",
    "        \n",
    "        #Escritura de los resultados del preprocesamiento\n",
    "        auxRes= pd.DataFrame({'Archivo': str(f).split('/')[-1], 'Tamaño(K)': [tmpSize], 'Cant Palabras Inicial': [tmpWordsOri],'Cant Palabras depuradas': [tmpWordsEnd],\"Vocabulario Inicial\":len(setWord),\"Vocabulario Final\":len(set_words)})\n",
    "        resultado = pd.concat([resultado, auxRes])\n",
    "    else:\n",
    "        print(aux + ':' + str(f))\n",
    "    break\n",
    "#resultado.to_csv(fileSummary, sep = ';', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'disequilibrium', 'kartik', 'homogen', 'collect', 'snitkin', 'tool', 'actuat', 'email', 'increas', 'experiment', 'sourc', 'aris', 'style', 'absorb', 'collett', 'carri', 'comp', 'model', 'passerini', 'freez', 'span', 'distinguish', 'four', 'appli', 'physic', 'verifi', 'spatial', 'shakhnovich', 'thermodynamischen', 'reduct', 'toward', 'quantum', 'lower', 'occur', 'physik', 'larger', 'within', 'xand', 'intelligent', 'microscop', 'shanghai', 'paper', 'arrow', 'simultan', 'purpos', 'unreach', 'zhu', 'object', 'without', 'human', 'gate', 'least', 'cube', 'relat', 'macroscop', 'grain', 'discuss', 'entropieverminderung', 'gc', 'respons', 'rna', 'indic', 'nandnor', 'superfamili', 'solid', 'motif', 'chromosom', 'kb', 'jiao', 'hu', 'quantiti', 'otherwis', 'percept', 'form', 'classif', 'enough', 'muld', 'design', 'becom', 'rd', 'spontan', 'trainlik', 'verif', 'delta', 'could', 'ri', 'twolink', 'gain', 'alon', 'doinatur', 'basic', 'ginestra', 'memori', 'suffici', 'state', 'stabl', 'element', 'valid', 'severini', 'notat', 'draw', 'orr', 'throughout', 'erasur', 'rimini', 'report', 'across', 'wesen', 'arrang', 'santa', 'histor', 'togeth', 'joseph', 'adler', 'industri', 'polym', 'xray', 'time', 'machin', 'articl', 'chklovskii', 'trace', 'biolog', 'sequenti', 'sergio', 'practic', 'landauer', 'logic', 'previou', 'accardi', 'pnasj', 'multipl', 'focu', 'top', 'conduct', 'schreiber', 'univers', 'previous', 'point', 'boltzmann', 'nat', 'peopl', 'might', 'label', 'vol', 'mathemat', 'yael', 'much', 'conjunct', 'connect', 'weight', 'issu', 'kroneck', 'weber', 'evan', 'devic', 'deeper', 'order', 'engin', 'ber', 'conflict', 'compon', 'shift', 'molecular', 'target', 'constant', 'set', 'theoret', 'pump', 'note', 'xor', 'technolog', 'loen', 'character', 'serv', 'artyom', 'leibler', 'forrest', 'instanti', 'tell', 'consist', 'unexplor', 'search', 'explain', 'area', 'prototyp', 'midpoint', 'momentarili', 'effici', 'earli', 'though', 'van', 'use', 'work', 'embed', 'accord', 'neuron', 'equal', 'caret', 'last', 'foundat', 'almost', 'thermodynam', 'evolutionari', 'statist', 'ribosom', 'must', 'ln', 'raoul', 'construct', 'pearl', 'diagram', 'brillouin', 'system', 'begin', 'lack', 'high', 'acid', 'shenorr', 'die', 'correspond', 'perhap', 'berlin', 'springer', 'lose', 'environ', 'gene', 'memoryless', 'circuit', 'graph', 'enumer', 'frank', 'road', 'structur', 'curios', 'brief', 'embodi', 'octob', 'divers', 'decemb', 'trivial', 'einem', 'school', 'acquir', 'section', 'signific', 'slight', 'descript', 'comment', 'neg', 'stage', 'declar', 'antoin', 'remain', 'charl', 'natur', 'increasingli', 'zeitschrift', 'experi', 'ashenberg', 'inform', 'matter', 'exist', 'exampl', 'level', 'build', 'dissip', 'visual', 'low', 'keyword', 'other', 'eugen', 'valentin', 'unifi', 'cours', 'exactli', 'china', 'involv', 'separ', 'stop', 'common', 'binari', 'sinc', 'invari', 'initi', 'express', 'abstractli', 'eric', 'zhenjun', 'simpl', 'sensori', 'path', 'milo', 'lume', 'unit', 'hedi', 'proteinprotein', 'geometri', 'simplest', 'modif', 'record', 'function', 'origin', 'bite', 'featur', 'explor', 'capac', 'sequenc', 'neumann', 'isotherm', 'circl', 'jame', 'network', 'appear', 'describ', 'research', 'address', 'account', 'entropydriven', 'constraint', 'condmatdisnn', 'mean', 'decreas', 'interest', 'delisi', 'control', 'loop', 'itzkovitz', 'conveni', 'equat', 'bacteri', 'present', 'eingriffen', 'reimand', 'photonmass', 'creation', 'heterogen', 'modul', 'discret', 'volum', 'peak', 'requir', 'tribu', 'creat', 'heat', 'block', 'suckjoon', 'szil', 'lesson', 'sensit', 'class', 'relationship', 'appropri', 'mani', 'possibl', 'differ', 'smallest', 'end', 'studi', 'ghirardi', 'investig', 'interpret', 'compar', 'ra', 'jess', 'peterson', 'fewer', 'thermostat', 'ubiqu', 'jun', 'introduct', 'front', 'simplic', 'vilo', 'interact', 'evolut', 'confin', 'graphabl', 'direction', 'follow', 'abstract', 'macro', 'absolut', 'case', 'toom', 'von', 'ideprint', 'reservoir', 'schneider', 'gener', 'anand', 'per', 'howev', 'consid', 'philip', 'bela', 'distinct', 'brian', 'journal', 'drain', 'three', 'exhibit', 'us', 'simon', 'arxivnlin', 'surpris', 'tradit', 'total', 'ciliberto', 'next', 'social', 'comput', 'scientif', 'nostrand', 'pattern', 'need', 'net', 'shmuel', 'yield', 'ge', 'melt', 'base', 'process', 'ice', 'addit', 'implement', 'central', 'measur', 'mikhail', 'singl', 'kashtan', 'usa', 'also', 'read', 'ubiquit', 'longer', 'differenti', 'bottom', 'arakelyan', 'highli', 'evolv', 'prokopenko', 'architectur', 'associ', 'transit', 'graphlik', 'myron', 'filippo', 'dimension', 'beij', 'radiat', 'fabian', 'princip', 'ideal', 'contain', 'ron', 'organ', 'instanc', 'hyde', 'principl', 'fals', 'version', 'institut', 'first', 'distanc', 'develop', 'fe', 'nussinov', 'laur', 'sfi', 'arxiv', 'well', 'annal', 'integr', 'artak', 'theori', 'protein', 'correl', 'mine', 'nm', 'two', 'propos', 'chang', 'illustr', 'momentari', 'artzyrandrup', 'transfer', 'limit', 'show', 'type', 'irrevers', 'valu', 'pressur', 'output', 'feasibl', 'kullback', 'unidirect', 'complet', 'biox', 'tong', 'map', 'scale', 'repres', 'noth', 'elabor', 'except', 'microscal', 'intern', 'back', 'divid', 'ulrich', 'complex', 'huaiyu', 'pna', 'author', 'temperatur', 'framework', 'anoth', 'allow', 'delet', 'conclus', 'link', 'examin', 'coupl', 'would', 'suppl', 'sever', 'lutz', 'threshold', 'alreadi', 'unsurprisingli', 'directli', 'attain', 'nand', 'simplifi', 'interior', 'observ', 'probabl', 'priit', 'bistat', 'second', 'classifi', 'fine', 'transient', 'hold', 'refer', 'visant', 'rel', 'share', 'petrosyan', 'true', 'small', 'pathway', 'produc', 'park', 'figur', 'maximum', 'ww', 'negentropi', 'lizier', 'one', 'minimum', 'find', 'larg', 'jaak', 'page', 'collaps', 'thermal', 'bei', 'result', 'bioinformat', 'price', 'graphweb', 'biol', 'instantli', 'part', 'absorpt', 'applic', 'may', 'thoma', 'converg', 'recognit', 'receiv', 'input', 'entropi', 'new', 'cross', 'direct', 'dillenschneid', 'bianconi', 'energi', 'macroscal', 'emiss', 'berut', 'tini', 'defin', 'basi', 'line', 'split', 'scienc', 'topolog', 'deed', 'env', 'compos', 'avignon', 'nucleic', 'higher', 'conceptu'}\n"
     ]
    }
   ],
   "source": [
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Entropy NAND: Early Functional Completeness in Entropy Networks\\nForrest Fabian Jesse1,2*\\n1\\n\\nSchool of Computer and Information Technology, Beijing Jiao Tong University, Beijing,\\n100044, China\\n\\n2\\n\\nBio-X Institutes, Shanghai Jiao Tong University, Shanghai, 200240, China\\n\\n* Author to whom correspondence should be addressed; email: jesse@jesse.org;\\n\\nAbstract: An observer increases in relative entropy as it receives information from what it is\\nobserving. In a system of only an observer and the observed, an increase in the relative\\nentropy of the observer is a decrease in the relative entropy of the observed. Linking together\\nthese directional entropy disequilibriums we show that NAND and NOR functionality arise\\nin such networks at very low levels of complexity.\\nKeywords: observation; networks; entropy transfer; directed entropy; directed observation;\\nfunctionally complete; NAND, NOR\\n\\n1. Introduction\\nWe describe a simple structure of directed entropy transfer which we label an observation. This\\nobservation is the simplest network pattern of directional entropy transfer consisting of an observer and\\nan observed. The characterization of observation as a thermodynamic transfer has been well described\\npreviously [1, 2]. The resulting entropy generation from observation can transfer [3] in a network [4-8]. In\\nthe tiny networks we discuss, the resulting entropy differentials can be used to construct or find a NAND\\nor a NOR gate. NAND and NOR can both be found and are present in the same network structure,\\ndistinguished only by changing the threshold of the output. We focus only on the NAND gate here. The\\nthermodynamically actuated NAND gate is trivial to implement which points to the possibility that it\\nexists in nature.\\n\\nObservation is a source of entropy increase if it requires two states for an observer (a previous state\\nand a changed state) as the observer acquires information or is surprised. The unit surprisal [9] can be\\nused to measure how much information is acquired, where complete lack of surprise is a complete lack of\\ninformation transfer. The smallest surprise is a nat, the unit of entropy in base e. Entropy creation from\\nobservation has been described to have a minimum limit [1,10,11,12] of kB T ln 2 (kB is the Boltzmann\\nconstant, T is absolute temperature, 2 represents the before and the after state) and this also defines the\\nminimum energy required to change a bit of information. The minimum limit has since been\\nexperimentally shown [12] to be valid. This entropy change has been characterized in the Brillouin\\n\\n\\x0cdescription of negentropy [1, (eq. 3)] for an observer which remains isothermal by radiating the entropy\\nincrease as thermal energy. The negentropy principal builds on previous work (Szilard [2] and others)\\nstating that the entropy of the observer is negative as entropy is transferred to the observer\\'s environment.\\n\\nInstances of the generation and transfer of entropy through observation can be linked together to\\nproduce an observation network model which we illustrate in figure 1. Entropy network structures have\\nbeen investigated previously [8,13,14]. A description of entropy transfer can be found in the Schreiber\\ntransfer entropy [3] which has been thermodynamically characterized by Prokopenko, Lizier & Price\\n[15].\\n\\nWe describe a discrete entropy transfer between two idealized elements which are entropy\\n\\ncontainers.\\nNetworks constructed from observations can be functionally complete, which we show in this article\\nby constructing a NAND gate from entropy transfers.\\n\\n2. Results and Discussion\\n2.0. Observers\\nWe propose our version of an observer as a discrete element which can change. By discrete we\\nmean having no relation with any other element, except through the relationship type which we\\ndescribe as an observation. We define element to be that which generates 1 nat of entropy in the\\nobserver when observed. The element is the prototype for possible thermodynamic disequilibrium,\\ninitially without internal differentiation. The interior of our prototypical element is homogeneous,\\nhaving no features to compare and so having no internal information, and no entropy. The first\\ndifferentiation in an element is the instantiation of disequilibrium that is a directed transfer of\\nentropy. As stated previously, entropy creation from observation has been described to have a\\nminimum limit [1,10,11,12] of kB T ln 2. We can set an appropriate temperature so that kB = 1\\nwhich simplifies the description of the entropy of the observer to:\\n\\nT ln m\\n\\n(1)\\n\\nwhere m is the quantity of states of the observer. Before observation, m = 1, through observation m\\n= 2 at least momentarily until the entropy is transferred into the environment. We can represent this\\nelement as a pattern that has no features, illustrated in figure 1.a as a circle where m = 1; and as a\\ndivided circle where m=2. Our small model system is shown in figure 1 and 2. We illustrate the\\nelement as a pattern that has no features in figure 1.a as a circle. An element in internal entropy\\ndisequilibrium as represented as a circle split into parts, figure 1.b labeled b1, b2, illustrated with\\nlines drawn through the circle enumerating the component states of disequilibrium. An example\\nshows two states and the simplest entropy disequilibrium in figure 1.b.\\n\\n\\x0c2.1. Observation of an object\\nOur version of observation of an object is a process in which the observer gains at least one bit of\\ninformation, and which is an entropy change. In a system of only the observer and the observed, this\\nrelative entropy change is described by 1 nat. We can find a physical description of the relation\\n(measuring temperature T, S is total summed entropy) as S=E/T as stated by Brillouin [1, (eq. 40)] where\\nthe total entropy increase from a single observation is described.\\n\\nWe equate the smallest entropy increase to the simplest differentiation of a discrete element, resulting\\nin an entropy increase of 1 nat. The entropy increase we describe as a split of the observer into two states\\nwhich we can describe as \"before observation\" and \"after observation\".\\n\\nIn the course of observation the complexity of the element is momentarily increased, which increases\\nits entropy in relation to those observers which observe it. This entropy must be dissipated to the\\nenvironment if the element is to remain isothermal, we represent the environment as another discrete\\nelement as defined previously, this is illustrated in the transfer network in figure 1.c\\n\\nThe graph of binary entropy H(p) shows entropy peaks between the beginning and ending states in a\\nsystem of one bit expressing a state change. This graph can be verified experimentally on a statistical\\nbasis. In this article we describe a “before” and an “after” state, and propose that the transition between\\nthese states follows the binary entropy graph through time, yielding maximum entropy at the theoretical\\nmidpoint of the transition. The transition between states for our simple element model is a momentary\\npeak at maximum entropy, which we describe as a Kronecker delta function that is 1 only at 0 (0 being\\nthe theoretical midpoint of the transition). For illustrative purposes we also describe in section 3 a\\nphysical example using ice cubes as entropy containers, in which the transition would need to occur over\\na longer span of time.\\n\\n2.2. Entropy transfer\\nThe minimum entropy transfer on observation is 1 nat which is a relative entropy reduction for the\\nobserved:\\nMinimum Entropy Transfer = 1 nat\\n\\n(2)\\n\\nMinimum Energy Required = kB Temperature ln 2 (Joules)\\nAt stable temperatures (isothermal conditions, in Joules) [10] this defines the minimum energy required to\\ntransfer one bit of information. For an isothermal system, if entropy has increased, such entropy must be\\nabsorbed by the environment, otherwise the system is not isothermal. When we model this transfer with\\n\\n\\x0cthe Kronecker delta, the absorption of new entropy appears to occur instantly for elements which are\\nconnected directly (with a network distance of 1)\\n\\n2.3. Entropy of erasure\\n\\nIf the system in which a bit is changed is small enough, and it has no memory, then changing a bit is\\ndeleting information. This deletion of information by the Landauer principle will require the dissipation\\nof heat of at least kB T ln 2 of heat per lost bit [13]. This dissipation interacts with the environment of the\\nobserver. In a small system where the environment is composed of only a single discrete element (figure\\n1.c), the dissipated entropy must be absorbed by this single element.\\n\\n2.4. Shifting entropy from the classified to the classifier\\nWhen a collection is classified, entropy shifts from the classified to the classifier, this process of\\nclassification from Kullback and Leibler [16] is an entropy reduction in the classified, and an entropy\\nincrease in the classifier. A single discrete element, which has capacity for only holding one bit of\\ninformation observes another element: if this discrete element is to receive information from what it has\\nobserved, it must change to another state which has a bit of information correlated with what it has\\nobserved. This correlation with what it has observed is a relationship which in the simplest case is\\nunidirectional. The smallest element is just 1 bit, with no memory. A memoryless 1 bit element may have\\nno record of the state change, and so by the Landauer principle we will find an increase in entropy in the\\nenvironment which is the classification system. This is again figure 1.c.\\n\\n2.5. Observation networks map entropy transfers\\nWe can conceptualize observation networks to map entropy transfers where at least one transfer\\ninvolves an observer. Entropy is a convenient quantity to map as it transitions through many networks\\nwhich are traditionally separate.\\n\\nWe can build observation networks as graph-like descriptions of the pathways of change between\\nelements, where the elements can then model objects, people, proteins, neurons or other graphable\\nsystems. Graphing tools for visualizing and using biological interaction networks [4-7], have been\\ndeveloped across the span of scales: from molecular and protein level interaction models [6] to models of\\nhuman interaction in social orders. Biological architectures in general have been abstractly characterized\\nas network models [7,8] .\\n\\n\\x0cIn the following diagrams we describe the creation of an element’s relationships with other elements.\\nThese elements are an accounting device which we can use to trace entropy transfer. An element can split\\ninto two elements (before and after) in the creation of a nat of entropy, which is an observation and the\\nsimplest relationship.\\n\\nEntropy before observation is Temperature ln 1 =0, as there are no relationships in the system (figure\\n1.a). We illustrate entropy networks elaborating possible networks up to network distance d = 2 (figures\\n1.c and 1.d; figure 2.d show to d = 2 ). Two simultaneous observations (d = 1) are sufficient to create an\\nentropy NAND gate (figure 3). Deeper exploration of observation network sequences is interesting but\\nremains unexplored here.\\n\\nFigure 1. Entropy Circuit. From top to bottom is shown a description of observation as\\ntargeted entropy generation and transfer. The circle represents an element with a single state.\\nThe divided circle represents an element with multiple states (before observation and after\\nobservation), being divided by a line for each additional state. The arrow indicates the target\\nof observation, the element at the origin of the arrow experiences a split into before and after\\nstates on observation represented by the arrow crossing the circle to show it divided.\\n\\na = T ln 1 = 0 nat\\nb = T ln 1 = 0 nat\\n\\na = T ln 1 = 0 nat\\nb = T ln 2 = 1 nat\\n\\na = T ln 1\\nb = T ln 2\\nenv ≥ T ln 2\\n\\n\\x0c2.6. Entropy transfer classes\\nWe can classify entropy network structures according to their entropy transfer directionality. This can\\nbe a simple means to classify simple patterns through entropy networks.\\n\\nEntropy networks are diverse. Entropy-driven organization occurs at least at the molecular scale [17].\\nEntropy is directed by people, ubiquitous in the practice of thermodynamic industry. People are sensitive\\nto entropy at large scales [18] and directly through sensory perception in the course of pattern recognition.\\nThese areas all express entropy networks, while a common classification of entropy network components\\nthroughout these systems is lacking. Classification by total entropy [19], has been examined [20] to\\nsearch for information. But using a measure of total entropy tells us nothing about what the net connects\\nto and how it is formed. Classification by connectivity has been carried out historically in the practice of\\ngeometry and related studies. Unsurprisingly, there are several basic transfer patterns from which other\\npatterns can be built. We classify them by how they transfer entropy, by linking together instances of\\nobservation.\\n\\nWe describe two classes, which we label first order and second order, the order is an indication of the\\nquantity of observations that compose the network. We stop at two. The first order contains only one\\npattern of observation, the single observation. The second order contains four patterns, which are all\\npossible patterns for two observations. In the second order, the only difference between networks is the\\ndirectionality of entropy transfer.\\n\\n2.7. A first order classification (all possible patterns for one observation)\\n1) The single observation. This is the simplest discrete entropy transfer describing a single element\\nsplitting into two states on observation of another element, creating entropy disequilibrium of 1 nat.\\n2.8. A second order classification (all possible patterns for two observations)\\nThis second order of classification is all possible patterns for two observations. The patterns have\\nequal complexity but each transfers entropy differently.\\n\\n1) Sequential entropy transfer (figure 2.d)\\n2) Loop of entropy transfer (figure 2.a)\\n3) A pattern in which two elements observe a common element, we label it e> . (figure 2.b)\\n4) A pattern in which an element is split through observation to observe two other elements, we label\\nit s< . (figure 2.c)\\n\\n\\x0cFigure 2. Two Observation Entropy Transfer Patterns. From top to bottom, we show all\\npossible patterns for two observations, which produces four distinct patterns each of which\\nhas a distinct entropy transfer direction.\\n\\ne = T ln 1\\na = T ln 2\\nb = T ln 2\\n\\ns = T ln 4\\na = T ln 1\\nb = T ln 1\\n\\np = T ln 1\\nb = T ln 2\\nc ≥ T ln 2\\n\\n2.9. Early functional completeness\\nAt very low complexity, we find that the second order observation network patterns exhibit functional\\ncompleteness. Excepting the loop, the second order (two observation) class is the functionally complete\\nNAND gate. Each of the patterns in this class serves as one of the four possibilities of the gate.\\nNAND state (inputs:11; output:0 ) is shown by the s< pattern shown in figure 2.c, which has two\\nelements being observed and so has lower relative entropy while their observer, being split through before\\nand after states has higher entropy.\\n\\n\\x0cNAND state (inputs:00; output:1) is shown in the e> pattern (figure 2.b), in which the central e element\\nis of low relative entropy because it is being observed by two other elements of higher relative entropy.\\nThe next two NAND states are represented by the two other possibilities that exist for the sequential,\\ntrain-like observation patterns that are 𝑏𝑡𝑟𝑎𝑖𝑛 (inputs:01; output:1) and 𝑎𝑡𝑟𝑎𝑖𝑛 (inputs:10; output:1). We\\ncan note that these last two patterns, being sequential, can only be distinguished (front to back or back to\\nfront) if the NAND gate is embedded within another network, which is appropriate because a logic gate\\nrequires input and output to be a gate.\\nFigure 3. NAND. From top to bottom each pattern represents a logical NAND gate state.\\nThe output of the gate is read from o. The inputs are a and b. The outputs should be\\nthresholded so that the logical false ≤ ½ and logical true > ½.\\n\\n𝑎 = 𝑜1\\n𝑏 = 𝑜2\\na = T ln 2\\nb = T ln 2\\no = T ln 1\\n𝑎=𝑜\\n𝑜=𝑏\\na ≥ T ln 2\\nb = T ln 1\\no = T ln 2\\n\\n𝑏=𝑜\\n𝑜=𝑎\\nb ≥ T ln 2\\na = T ln 1\\no = T ln 2\\n\\n𝑜 = 𝑎, 𝑏\\na = T ln 1\\nb = T ln 1\\no = T ln 4\\n\\n\\x0cIn the following expressions we use the caret notation (a hat) to represent that an element is the\\nobservation of another element, for example 𝑎 = 𝑜1 means that 𝑎 is the observation of 𝑜1 .\\n𝑎 = 𝑜1 ; 𝑎𝑆 ≥ T ln 2\\n𝑒 > = 𝑏 = 𝑜2 ; 𝑏𝑆 ≥ T ln 2\\n𝑜𝑆 = T ln 1\\n\\n(3)\\n\\n𝑎𝑆 = T ln 1\\n𝑏𝑆 = T ln 1\\n𝑠 =\\n𝑜 = 𝑎 𝑏; 𝑜𝑆 ≥ T ln 4\\n\\n(4)\\n\\n𝑎 = 𝑜; 𝑎𝑆 ≥ T ln 2\\n𝑏𝑆 = T ln 1\\n𝑏𝑡𝑟𝑎𝑖𝑛 =\\n𝑜 = 𝑏; 𝑜𝑆 ≥ T ln 2\\n\\n(5)\\n\\n𝑎𝑆 = T ln 1\\n𝑎𝑡𝑟𝑎𝑖𝑛 = 𝑏 = 𝑜; 𝑏𝑆 ≥ T ln 2\\n𝑜 = 𝑎 ; 𝑜𝑆 = T ln 2\\n\\n(6)\\n\\n<\\n\\n3. Discussion\\nTo physically embody this NAND system would require the embodiment of elements which can\\ncontain entropy. In our simple example we use discrete elements which have discrete entropy values,\\nthese values are controlled by the direction of entropy transfer between elements. A macro-scale\\nimplementation of this could be constructed, but would become statistical as the thermodynamic transfers\\nwould be of higher energies and not discrete observations.\\nIn a possible experimental implementation our simple elements could be embodied by ice cubes which\\nare thermodynamic heat reservoirs, and entropy transfer could be arranged by heat pumping, thermally\\nconductive paths between the reservoirs. Two ice cubes are inputs which are connected to a central ice\\ncube by a thermal pump, and the central ice cube is a NAND output. For our macro-scale implementation,\\nthe thermal coupling must be a directionally controllable entropy pump, which could be implemented as a\\nheat pump (thermal transfer engine).\\nThe three elements that compose our NAND gate are then three ice cubes. Entropy increase,\\nconsidering constant volume and pressure would then be a temperature increase, and high entropy ice\\ncubes would melt. Low entropy ice cubes would be solid. In the two-link (two observation) network that\\nwe have described, if we are to drain the entropy from two ice cubes (figure 2.b), the central ice cube\\n(represented in figure 2.b as element e) must absorb the entropy, and melt. If we are to drain the entropy\\n\\n\\x0cfrom the central ice cube into the other two (figure 2.b), they must increase in entropy and melt while the\\ncentral ice cube (e) freezes.\\n\\nWe note that within a quantity of exactly 2 observations, NAND is possible with output thresholded so\\nthat the logical false ≤ ½ and logical true > ½. NOR is possible with a slight modification of this\\nthreshold. AND, OR, XAND and XOR are unreachable with two observation networks, they require more\\nthan 2 observations for implementation. That discrete observation entropy networks can attain functional\\ncompleteness almost instantly may be but a curiosity. However, the statistical, thermodynamic\\nNAND/NOR produces the same functionality in the macro scale, and the thermodynamic gate would\\nshare in the physical ubiquity of thermodynamic transfer.\\n\\nThe energy associated with a single observation and it\\'s relation to relative entropy in quantum models\\nwas already noted by Brillouin in 1953. It has been increasingly accounted for in quantum collapse\\nmodels [21-22]. Huaiyu Zhu [23] and others have described the entropy of photon-mass absorption, and\\nthough this description is a larger scale entropy transfer than that in the observation networks model\\npresented here, photon-mass entropy transfer might allow an experimentally feasible micro-scale\\ncharacterization of entropy transfer at the quantum scale. Entropy reduction is a collapse of multiple states\\nto fewer states. This feature of collapse, in conjunction with entropy NAND perhaps points to the\\npossibility of fine grained computational style structures with physical results.\\n\\nThe thermodynamic NAND which follows from entropy NAND points to the existence of scale\\ninvariant computationally functional entropy transfer networks and proposes ubiquitous computation\\noccurring throughout such networks.\\n\\n4. Conclusions\\nThermodynamic entropy networks are ubiquitous. Our simple characterization of entropy networks shows\\nthat at a very early stage of complexity functional completeness can be produced. As noted in the\\nintroduction, the thermodynamic NAND gate is trivial to construct, and because of this simplicity it may\\nbe present in nature.\\nConflicts of Interest\\nThe authors declare no conflict of interest.\\nReferences and Notes\\n\\n\\x0c1.\\n\\nL. Brillouin. “The Negentropy Principal of Information.” Journal of Applied Physics, Vol. 24, No.\\n9, Pages 1152-1163.\\n\\n2.\\n\\nL. Szilárd. \"Über die Entropieverminderung in einem thermodynamischen System bei Eingriffen\\nintelligenter Wesen.\" Zeitschrift für Physik, Vol. 53, Pages 840-856. (1929)\\n\\n3.\\n\\nThomas Schreiber. “Measuring Information Transfer.” arXiv:nlin/0001042 [nlin.CD]\\n\\n4.\\n\\nJüri Reimand, Laur Tooming, Hedi Peterson, Priit Adler and Jaak Vilo. “GraphWeb: mining\\nheterogeneous biological networks for gene modules with functional significance.” Nucleic Acids\\nResearch Vol. 36, Issue suppl. 2, Pages W452–W459.\\n\\n5.\\n\\nZhenjun Hu, Evan S. Snitkin and Charles DeLisi. “VisANT: an integrative framework for networks\\nin systems biology.” Briefings in Bioinformatics Vol. 9, Issue 4, Pages 317–325.\\n\\n6.\\n\\nEric J. Deeds, Orr Ashenberg, and Eugene I. Shakhnovich. “A simple physical model for scaling in\\nprotein–protein interaction networks.” PNASJ, Vol. 103, No. 2, Pages 311–316.\\n\\n7.\\n\\nJames W. Valentine. “Architectures of Biological Complexity.” Integr. Comp. Biol., Vol. 43, Pages\\n99–103.\\n\\n8.\\n\\nR. Milo, S. Shen-Orr, S. Itzkovitz, N. Kashtan, D. Chklovskii, U. Alon. “Network Motifs: Simple\\nBuilding Blocks of Complex Networks.” Science 298, 824 (2002).\\n\\n9.\\n\\nTribus, Myron. \"Thermostatics and Thermodynamics: an Introduction to Energy, Information and\\nStates of Matter, with Engineering Applications.\" Van Nostrand. (1961)\\n\\n10.\\n\\nThomas D. Schneider. “70% efficiency of bistate molecular machines explained by information\\ntheory, high dimensional geometry and evolutionary convergence.” Nucleic Acids Research, 2010,\\nVol. 38, No. 18, Pages 5995–6006.\\n\\n11.\\n\\nMikhail Prokopenko & Joseph T. Lizier. “Transfer Entropy and Transient Limits of Computation.”\\nNature Scientific Reports. Vol. 4:5394.\\n\\n12.\\n\\nAntoine Be´rut, Artak Arakelyan, Artyom Petrosyan, Sergio Ciliberto, Raoul Dillenschneider &\\nEric Lutz. “Experimental verification of Landauer’s principle linking information and\\nthermodynamics.”\\n\\nNature, Vol. 483, Pages 187-189. doi:10.1038/nature10872.\\n\\n\\x0c13.\\n\\nYael Artzy-Randrup et al. “Comment on \\'Network Motifs: Simple Building Blocks of Complex\\nNetworks\\' and \"Superfamilies of Evolved and Designed Networks.” Science 305, 1107 (2004).\\n\\n14.\\n\\nRon Milo et al. “Response to Comment on \"Network Motifs: Simple Building Blocks of Complex\\nNetworks” and \"Superfamilies of Evolved and Designed.\" Science 305, 1107 (2004).\\n\\n15.\\n\\nProkopenko, M., Lizier, J. T. & Price, D. C. “On thermodynamic interpretation of transfer\\nentropy. ” Entropy, Vol. 15, 524–543. (2013)\\n\\n16.\\n\\nKullback, S., Leibler, R.A. “On Information and Sufficiency.” Annals of Mathematical Statistics. 22\\n(1). Pages 79–86. (1951)\\n\\n17.\\n\\nSuckjoon Jun and Bela Mulde. “Entropy-driven spatial organization of highly confined polymers:\\nLessons for the bacterial chromosome.” PNAS, 12388–12393, vol. 103 no. 33.\\n\\n18.\\n\\nUlrich E. “Molecular weights of ribosomal RNA in relation to evolution.” Loening Journal of\\nMolecular Biology. lume 38, Issue 3, 28 December 1968, Pages 355–365.\\n\\n19.\\n\\nFilippo Passerini and Simone Severini,. “The von Neumann entropy of networks.”\\nhttp://mpra.ub.uni-muenchen.de/id/eprint/12538.\\n\\n20.\\n\\nKartik Anand and Ginestra Bianconi. “Entropy measures for networks: Toward an information\\ntheory of complex topologies”. arXiv:0907.1514 [cond-mat.dis-nn].\\n\\n21.\\n\\nGhirardi, G.C., Rimini, A., and Weber, T. “A Model for a Unified Quantum Description of\\nMacroscopic and Microscopic Systems”. Quantum Probability and Applications, L. Accardi et al.\\n(eds), Springer, Berlin. (1985)\\n\\n22.\\n\\nBrian Collett, Philip Pearle, Frank Avignone, Shmuel Nussinov. “Constraint on collapse models by\\nlimit on spontaneous x-ray emission in Ge.” Foundations of Physics, October 1995, Volume 25,\\nIssue 10, Pages 1399-1412.\\n\\n23.\\n\\nHuaiyu Zhu. “On Irreversible Radiation Processes.” SFI Working Paper: 1997-03-022. Santa Fe\\nInstitute, 1399 Hyde Park Road, Santa Fe, NM 87501, USA. (1997)\\n\\n\\x0c'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'absolut',\n",
       " 'absorb',\n",
       " 'absorpt',\n",
       " 'abstract',\n",
       " 'abstractli',\n",
       " 'accardi',\n",
       " 'accord',\n",
       " 'account',\n",
       " 'acid',\n",
       " 'acquir',\n",
       " 'across',\n",
       " 'actuat',\n",
       " 'addit',\n",
       " 'address',\n",
       " 'adler',\n",
       " 'allow',\n",
       " 'almost',\n",
       " 'alon',\n",
       " 'alreadi',\n",
       " 'also',\n",
       " 'anand',\n",
       " 'annal',\n",
       " 'anoth',\n",
       " 'antoin',\n",
       " 'appear',\n",
       " 'appli',\n",
       " 'applic',\n",
       " 'appropri',\n",
       " 'arakelyan',\n",
       " 'architectur',\n",
       " 'area',\n",
       " 'aris',\n",
       " 'arrang',\n",
       " 'arrow',\n",
       " 'artak',\n",
       " 'articl',\n",
       " 'artyom',\n",
       " 'artzyrandrup',\n",
       " 'arxiv',\n",
       " 'arxivnlin',\n",
       " 'ashenberg',\n",
       " 'associ',\n",
       " 'attain',\n",
       " 'author',\n",
       " 'avignon',\n",
       " 'back',\n",
       " 'bacteri',\n",
       " 'base',\n",
       " 'basi',\n",
       " 'basic',\n",
       " 'becom',\n",
       " 'begin',\n",
       " 'bei',\n",
       " 'beij',\n",
       " 'bela',\n",
       " 'ber',\n",
       " 'berlin',\n",
       " 'berut',\n",
       " 'bianconi',\n",
       " 'binari',\n",
       " 'bioinformat',\n",
       " 'biol',\n",
       " 'biolog',\n",
       " 'biox',\n",
       " 'bistat',\n",
       " 'bite',\n",
       " 'block',\n",
       " 'boltzmann',\n",
       " 'bottom',\n",
       " 'brian',\n",
       " 'brief',\n",
       " 'brillouin',\n",
       " 'build',\n",
       " 'capac',\n",
       " 'caret',\n",
       " 'carri',\n",
       " 'case',\n",
       " 'central',\n",
       " 'chang',\n",
       " 'character',\n",
       " 'charl',\n",
       " 'china',\n",
       " 'chklovskii',\n",
       " 'chromosom',\n",
       " 'ciliberto',\n",
       " 'circl',\n",
       " 'circuit',\n",
       " 'class',\n",
       " 'classif',\n",
       " 'classifi',\n",
       " 'collaps',\n",
       " 'collect',\n",
       " 'collett',\n",
       " 'comment',\n",
       " 'common',\n",
       " 'comp',\n",
       " 'compar',\n",
       " 'complet',\n",
       " 'complex',\n",
       " 'compon',\n",
       " 'compos',\n",
       " 'comput',\n",
       " 'conceptu',\n",
       " 'conclus',\n",
       " 'condmatdisnn',\n",
       " 'conduct',\n",
       " 'confin',\n",
       " 'conflict',\n",
       " 'conjunct',\n",
       " 'connect',\n",
       " 'consid',\n",
       " 'consist',\n",
       " 'constant',\n",
       " 'constraint',\n",
       " 'construct',\n",
       " 'contain',\n",
       " 'control',\n",
       " 'conveni',\n",
       " 'converg',\n",
       " 'correl',\n",
       " 'correspond',\n",
       " 'could',\n",
       " 'coupl',\n",
       " 'cours',\n",
       " 'creat',\n",
       " 'creation',\n",
       " 'cross',\n",
       " 'cube',\n",
       " 'curios',\n",
       " 'decemb',\n",
       " 'declar',\n",
       " 'decreas',\n",
       " 'deed',\n",
       " 'deeper',\n",
       " 'defin',\n",
       " 'delet',\n",
       " 'delisi',\n",
       " 'delta',\n",
       " 'describ',\n",
       " 'descript',\n",
       " 'design',\n",
       " 'develop',\n",
       " 'devic',\n",
       " 'diagram',\n",
       " 'die',\n",
       " 'differ',\n",
       " 'differenti',\n",
       " 'dillenschneid',\n",
       " 'dimension',\n",
       " 'direct',\n",
       " 'direction',\n",
       " 'directli',\n",
       " 'discret',\n",
       " 'discuss',\n",
       " 'disequilibrium',\n",
       " 'dissip',\n",
       " 'distanc',\n",
       " 'distinct',\n",
       " 'distinguish',\n",
       " 'divers',\n",
       " 'divid',\n",
       " 'doinatur',\n",
       " 'drain',\n",
       " 'draw',\n",
       " 'earli',\n",
       " 'effici',\n",
       " 'einem',\n",
       " 'eingriffen',\n",
       " 'elabor',\n",
       " 'element',\n",
       " 'email',\n",
       " 'embed',\n",
       " 'embodi',\n",
       " 'emiss',\n",
       " 'end',\n",
       " 'energi',\n",
       " 'engin',\n",
       " 'enough',\n",
       " 'entropi',\n",
       " 'entropieverminderung',\n",
       " 'entropydriven',\n",
       " 'enumer',\n",
       " 'env',\n",
       " 'environ',\n",
       " 'equal',\n",
       " 'equat',\n",
       " 'erasur',\n",
       " 'eric',\n",
       " 'eugen',\n",
       " 'evan',\n",
       " 'evolut',\n",
       " 'evolutionari',\n",
       " 'evolv',\n",
       " 'exactli',\n",
       " 'examin',\n",
       " 'exampl',\n",
       " 'except',\n",
       " 'exhibit',\n",
       " 'exist',\n",
       " 'experi',\n",
       " 'experiment',\n",
       " 'explain',\n",
       " 'explor',\n",
       " 'express',\n",
       " 'fabian',\n",
       " 'fals',\n",
       " 'fe',\n",
       " 'feasibl',\n",
       " 'featur',\n",
       " 'fewer',\n",
       " 'figur',\n",
       " 'filippo',\n",
       " 'find',\n",
       " 'fine',\n",
       " 'first',\n",
       " 'focu',\n",
       " 'follow',\n",
       " 'form',\n",
       " 'forrest',\n",
       " 'foundat',\n",
       " 'four',\n",
       " 'framework',\n",
       " 'frank',\n",
       " 'freez',\n",
       " 'front',\n",
       " 'function',\n",
       " 'gain',\n",
       " 'gate',\n",
       " 'gc',\n",
       " 'ge',\n",
       " 'gene',\n",
       " 'gener',\n",
       " 'geometri',\n",
       " 'ghirardi',\n",
       " 'ginestra',\n",
       " 'grain',\n",
       " 'graph',\n",
       " 'graphabl',\n",
       " 'graphlik',\n",
       " 'graphweb',\n",
       " 'heat',\n",
       " 'hedi',\n",
       " 'heterogen',\n",
       " 'high',\n",
       " 'higher',\n",
       " 'highli',\n",
       " 'histor',\n",
       " 'hold',\n",
       " 'homogen',\n",
       " 'howev',\n",
       " 'hu',\n",
       " 'huaiyu',\n",
       " 'human',\n",
       " 'hyde',\n",
       " 'ice',\n",
       " 'ideal',\n",
       " 'ideprint',\n",
       " 'illustr',\n",
       " 'implement',\n",
       " 'increas',\n",
       " 'increasingli',\n",
       " 'indic',\n",
       " 'industri',\n",
       " 'inform',\n",
       " 'initi',\n",
       " 'input',\n",
       " 'instanc',\n",
       " 'instanti',\n",
       " 'instantli',\n",
       " 'institut',\n",
       " 'integr',\n",
       " 'intelligent',\n",
       " 'interact',\n",
       " 'interest',\n",
       " 'interior',\n",
       " 'intern',\n",
       " 'interpret',\n",
       " 'introduct',\n",
       " 'invari',\n",
       " 'investig',\n",
       " 'involv',\n",
       " 'irrevers',\n",
       " 'isotherm',\n",
       " 'issu',\n",
       " 'itzkovitz',\n",
       " 'jaak',\n",
       " 'jame',\n",
       " 'jess',\n",
       " 'jiao',\n",
       " 'joseph',\n",
       " 'journal',\n",
       " 'jun',\n",
       " 'kartik',\n",
       " 'kashtan',\n",
       " 'kb',\n",
       " 'keyword',\n",
       " 'kroneck',\n",
       " 'kullback',\n",
       " 'label',\n",
       " 'lack',\n",
       " 'landauer',\n",
       " 'larg',\n",
       " 'larger',\n",
       " 'last',\n",
       " 'laur',\n",
       " 'least',\n",
       " 'leibler',\n",
       " 'lesson',\n",
       " 'level',\n",
       " 'limit',\n",
       " 'line',\n",
       " 'link',\n",
       " 'lizier',\n",
       " 'ln',\n",
       " 'loen',\n",
       " 'logic',\n",
       " 'longer',\n",
       " 'loop',\n",
       " 'lose',\n",
       " 'low',\n",
       " 'lower',\n",
       " 'lume',\n",
       " 'lutz',\n",
       " 'machin',\n",
       " 'macro',\n",
       " 'macroscal',\n",
       " 'macroscop',\n",
       " 'mani',\n",
       " 'map',\n",
       " 'mathemat',\n",
       " 'matter',\n",
       " 'maximum',\n",
       " 'may',\n",
       " 'mean',\n",
       " 'measur',\n",
       " 'melt',\n",
       " 'memori',\n",
       " 'memoryless',\n",
       " 'microscal',\n",
       " 'microscop',\n",
       " 'midpoint',\n",
       " 'might',\n",
       " 'mikhail',\n",
       " 'milo',\n",
       " 'mine',\n",
       " 'minimum',\n",
       " 'model',\n",
       " 'modif',\n",
       " 'modul',\n",
       " 'molecular',\n",
       " 'momentari',\n",
       " 'momentarili',\n",
       " 'motif',\n",
       " 'much',\n",
       " 'muld',\n",
       " 'multipl',\n",
       " 'must',\n",
       " 'myron',\n",
       " 'nand',\n",
       " 'nandnor',\n",
       " 'nat',\n",
       " 'natur',\n",
       " 'need',\n",
       " 'neg',\n",
       " 'negentropi',\n",
       " 'net',\n",
       " 'network',\n",
       " 'neumann',\n",
       " 'neuron',\n",
       " 'new',\n",
       " 'next',\n",
       " 'nm',\n",
       " 'nostrand',\n",
       " 'notat',\n",
       " 'note',\n",
       " 'noth',\n",
       " 'nucleic',\n",
       " 'nussinov',\n",
       " 'object',\n",
       " 'observ',\n",
       " 'occur',\n",
       " 'octob',\n",
       " 'one',\n",
       " 'order',\n",
       " 'organ',\n",
       " 'origin',\n",
       " 'orr',\n",
       " 'other',\n",
       " 'otherwis',\n",
       " 'output',\n",
       " 'page',\n",
       " 'paper',\n",
       " 'park',\n",
       " 'part',\n",
       " 'passerini',\n",
       " 'path',\n",
       " 'pathway',\n",
       " 'pattern',\n",
       " 'peak',\n",
       " 'pearl',\n",
       " 'peopl',\n",
       " 'per',\n",
       " 'percept',\n",
       " 'perhap',\n",
       " 'peterson',\n",
       " 'petrosyan',\n",
       " 'philip',\n",
       " 'photonmass',\n",
       " 'physic',\n",
       " 'physik',\n",
       " 'pna',\n",
       " 'pnasj',\n",
       " 'point',\n",
       " 'polym',\n",
       " 'possibl',\n",
       " 'practic',\n",
       " 'present',\n",
       " 'pressur',\n",
       " 'previou',\n",
       " 'previous',\n",
       " 'price',\n",
       " 'priit',\n",
       " 'princip',\n",
       " 'principl',\n",
       " 'probabl',\n",
       " 'process',\n",
       " 'produc',\n",
       " 'prokopenko',\n",
       " 'propos',\n",
       " 'protein',\n",
       " 'proteinprotein',\n",
       " 'prototyp',\n",
       " 'pump',\n",
       " 'purpos',\n",
       " 'quantiti',\n",
       " 'quantum',\n",
       " 'ra',\n",
       " 'radiat',\n",
       " 'raoul',\n",
       " 'rd',\n",
       " 'read',\n",
       " 'receiv',\n",
       " 'recognit',\n",
       " 'record',\n",
       " 'reduct',\n",
       " 'refer',\n",
       " 'reimand',\n",
       " 'rel',\n",
       " 'relat',\n",
       " 'relationship',\n",
       " 'remain',\n",
       " 'report',\n",
       " 'repres',\n",
       " 'requir',\n",
       " 'research',\n",
       " 'reservoir',\n",
       " 'respons',\n",
       " 'result',\n",
       " 'ri',\n",
       " 'ribosom',\n",
       " 'rimini',\n",
       " 'rna',\n",
       " 'road',\n",
       " 'ron',\n",
       " 'santa',\n",
       " 'scale',\n",
       " 'schneider',\n",
       " 'school',\n",
       " 'schreiber',\n",
       " 'scienc',\n",
       " 'scientif',\n",
       " 'search',\n",
       " 'second',\n",
       " 'section',\n",
       " 'sensit',\n",
       " 'sensori',\n",
       " 'separ',\n",
       " 'sequenc',\n",
       " 'sequenti',\n",
       " 'sergio',\n",
       " 'serv',\n",
       " 'set',\n",
       " 'sever',\n",
       " 'severini',\n",
       " 'sfi',\n",
       " 'shakhnovich',\n",
       " 'shanghai',\n",
       " 'share',\n",
       " 'shenorr',\n",
       " 'shift',\n",
       " 'shmuel',\n",
       " 'show',\n",
       " 'signific',\n",
       " 'simon',\n",
       " 'simpl',\n",
       " 'simplest',\n",
       " 'simplic',\n",
       " 'simplifi',\n",
       " 'simultan',\n",
       " 'sinc',\n",
       " 'singl',\n",
       " 'slight',\n",
       " 'small',\n",
       " 'smallest',\n",
       " 'snitkin',\n",
       " 'social',\n",
       " 'solid',\n",
       " 'sourc',\n",
       " 'span',\n",
       " 'spatial',\n",
       " 'split',\n",
       " 'spontan',\n",
       " 'springer',\n",
       " 'stabl',\n",
       " 'stage',\n",
       " 'state',\n",
       " 'statist',\n",
       " 'stop',\n",
       " 'structur',\n",
       " 'studi',\n",
       " 'style',\n",
       " 'suckjoon',\n",
       " 'suffici',\n",
       " 'superfamili',\n",
       " 'suppl',\n",
       " 'surpris',\n",
       " 'system',\n",
       " 'szil',\n",
       " 'target',\n",
       " 'technolog',\n",
       " 'tell',\n",
       " 'temperatur',\n",
       " 'theoret',\n",
       " 'theori',\n",
       " 'thermal',\n",
       " 'thermodynam',\n",
       " 'thermodynamischen',\n",
       " 'thermostat',\n",
       " 'thoma',\n",
       " 'though',\n",
       " 'three',\n",
       " 'threshold',\n",
       " 'throughout',\n",
       " 'time',\n",
       " 'tini',\n",
       " 'togeth',\n",
       " 'tong',\n",
       " 'tool',\n",
       " 'toom',\n",
       " 'top',\n",
       " 'topolog',\n",
       " 'total',\n",
       " 'toward',\n",
       " 'trace',\n",
       " 'tradit',\n",
       " 'trainlik',\n",
       " 'transfer',\n",
       " 'transient',\n",
       " 'transit',\n",
       " 'tribu',\n",
       " 'trivial',\n",
       " 'true',\n",
       " 'two',\n",
       " 'twolink',\n",
       " 'type',\n",
       " 'ubiqu',\n",
       " 'ubiquit',\n",
       " 'ulrich',\n",
       " 'unexplor',\n",
       " 'unidirect',\n",
       " 'unifi',\n",
       " 'unit',\n",
       " 'univers',\n",
       " 'unreach',\n",
       " 'unsurprisingli',\n",
       " 'us',\n",
       " 'usa',\n",
       " 'use',\n",
       " 'valentin',\n",
       " 'valid',\n",
       " 'valu',\n",
       " 'van',\n",
       " 'verif',\n",
       " 'verifi',\n",
       " 'version',\n",
       " 'vilo',\n",
       " 'visant',\n",
       " 'visual',\n",
       " 'vol',\n",
       " 'volum',\n",
       " 'von',\n",
       " 'weber',\n",
       " 'weight',\n",
       " 'well',\n",
       " 'wesen',\n",
       " 'within',\n",
       " 'without',\n",
       " 'work',\n",
       " 'would',\n",
       " 'ww',\n",
       " 'xand',\n",
       " 'xor',\n",
       " 'xray',\n",
       " 'yael',\n",
       " 'yield',\n",
       " 'zeitschrift',\n",
       " 'zhenjun',\n",
       " 'zhu'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Archivo</th>\n",
       "      <th>Tamaño(K)</th>\n",
       "      <th>Cant Palabras Inicial</th>\n",
       "      <th>Cant Palabras depuradas</th>\n",
       "      <th>Vocabulario Inicial</th>\n",
       "      <th>Vocabulario Final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1410.2670.txt</td>\n",
       "      <td>24</td>\n",
       "      <td>3926</td>\n",
       "      <td>3487</td>\n",
       "      <td>939</td>\n",
       "      <td>608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Archivo  Tamaño(K)  Cant Palabras Inicial  Cant Palabras depuradas  \\\n",
       "0  1410.2670.txt         24                   3926                     3487   \n",
       "\n",
       "   Vocabulario Inicial  Vocabulario Final  \n",
       "0                  939                608  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "608"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construcción del Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.sparse import vstack,save_npz,load_npz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construido el vocabulario podemos construir el bag of words, que se hace con la ayuda de la funcion CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer = \"word\",vocabulary =vocabulary , tokenizer = None, preprocessor = None, stop_words = 'english', max_features = 5000) \n",
    "train_data_features = vectorizer.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "608"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_npz('sparse_matrix.npz', train_data_features)\n",
    "#sparse_matrix = load_npz('sparse_matrix.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vocabulary.txt', 'w') as f:\n",
    "    for item in vectorizer.get_feature_names():\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'BoW1.sav'\n",
    "pickle.dump(vectorizer, open(filename, 'wb'))\n",
    "#loaded_model = pickle.load(open('BoW1.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#words = set(nltk.corpus.words.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(vocabulary - words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.6(conda)",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
